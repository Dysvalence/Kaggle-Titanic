{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load CSVs as lists of lists of strings\n",
    "#Later on the training set is split up to make a validation set, so we're shuffling it here before any further processing\n",
    "\n",
    "import csv\n",
    "import numpy\n",
    "\n",
    "\n",
    "trainraw = []\n",
    "testraw = []\n",
    "\n",
    "with open('./Titanic/train.csv', 'rb') as traincsv:\n",
    "    trainreader = csv.reader(traincsv, delimiter=',', quotechar='|')\n",
    "    for row in trainreader:\n",
    "        #print ', '.join(row)\n",
    "        #print row\n",
    "        trainraw.append(row)\n",
    "        \n",
    "with open('./Titanic/test.csv', 'rb') as testcsv:\n",
    "    testreader = csv.reader(testcsv, delimiter=',', quotechar='|')\n",
    "    for row in testreader:\n",
    "        #print ', '.join(row)\n",
    "        #print row\n",
    "        testraw.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Age field has missing data values; this calculates the average and uses that as a replacement\n",
    "I tried culling the data but it didn't really make a big difference on NNs, \n",
    "but might make a difference in some of the other algorithms I wanted to try.\n",
    "The kaggle forums suggest extrapolating age from names and the other data, I'd probably try that next\n",
    "\"\"\"\n",
    "trainAgeAvg=-1\n",
    "testAgeAvg=-1\n",
    "trainAges=[]\n",
    "testAges=[]\n",
    "\n",
    "for x in range(1, len(trainraw)):\n",
    "    try:\n",
    "        trainAges.append(int(trainraw[x][6]))\n",
    "    except ValueError:\n",
    "        pass\n",
    "for x in range(1, len(testraw)):\n",
    "    try:\n",
    "        testAges.append(int(testraw[x][5]))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "trainAgeAvg=numpy.mean(trainAges)\n",
    "testAgeAvg=numpy.mean(testAges)\n",
    "\n",
    "#print trainAgeAvg\n",
    "#print testAgeAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data cleanup for training data, changing things to float, with one-hot encoding and dummy variables as needed.\n",
    "Cabin and ticket data are discarded due to so many missing fields. Assuming blanks in the fare field meant free passage.\n",
    "\"\"\"\n",
    "\n",
    "traindat=[]\n",
    "for x in range(1, len(trainraw)):\n",
    "    temp=[]\n",
    "       \n",
    "    if(trainraw[x][2]=='1'):\n",
    "        temp.append(1.0)\n",
    "        temp.append(0.0)\n",
    "        temp.append(0.0)\n",
    "    if(trainraw[x][2]=='2'):\n",
    "        temp.append(0.0)\n",
    "        temp.append(1.0)\n",
    "        temp.append(0.0)\n",
    "    if(trainraw[x][2]=='3'):\n",
    "        temp.append(0.0)\n",
    "        temp.append(0.0)\n",
    "        temp.append(1.0)\n",
    "    \n",
    "    if(trainraw[x][5]==\"male\"):\n",
    "        temp.append(0.0)\n",
    "    elif(trainraw[x][5]==\"female\"):\n",
    "        temp.append(1.0)\n",
    "    else:\n",
    "        temp.append(2)\n",
    "        print (\"shit happened\")\n",
    "        \n",
    "    try:\n",
    "        temp.append(float(trainraw[x][6])) #age\n",
    "    except ValueError:\n",
    "        temp.append(trainAgeAvg)\n",
    "       \n",
    "    temp.append(float(trainraw[x][7])) #Siblings/Spouse?\n",
    "    \n",
    "    temp.append(float(trainraw[x][8])) #Parent/Child\n",
    "    \n",
    "    try:\n",
    "        temp.append(float(trainraw[x][10])) #fare\n",
    "    except ValueError:\n",
    "        temp.append(0)\n",
    "        \n",
    "    if(trainraw[x][12]=='S'):\n",
    "        temp.append(1.0)\n",
    "        temp.append(0.0)\n",
    "        temp.append(0.0)\n",
    "    if(trainraw[x][12]=='C'):\n",
    "        temp.append(0.0)\n",
    "        temp.append(1.0)\n",
    "        temp.append(0.0)\n",
    "    if(trainraw[x][12]=='Q'):\n",
    "        temp.append(0.0)\n",
    "        temp.append(0.0)\n",
    "        temp.append(1.0)\n",
    "    \n",
    "    #print temp\n",
    "    #temp2=[]\n",
    "    #temp2.append(temp)\n",
    "    #temp2.append(trainraw[x][1])\n",
    "    #temp2.append(trainraw[x][0])\n",
    "    #traindat.append(temp2)\n",
    "    traindat.append((temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data cleanup for test data, changing things to float, with one-hot encoding and dummy variables as needed\n",
    "Cabin and ticket data are discarded due to so many missing fields. Assuming blanks in the fare field meant free passage.\n",
    "\"\"\"\n",
    "\n",
    "testdat=[]\n",
    "for x in range(1, len(testraw)):\n",
    "    temp=[]\n",
    "    \n",
    "    if(testraw[x][1]=='1'):\n",
    "        temp.append(1)\n",
    "        temp.append(0)\n",
    "        temp.append(0)\n",
    "    if(testraw[x][1]=='2'):\n",
    "        temp.append(0)\n",
    "        temp.append(1)\n",
    "        temp.append(0)\n",
    "    if(testraw[x][1]=='3'):\n",
    "        temp.append(0)\n",
    "        temp.append(0)\n",
    "        temp.append(1)\n",
    "    \n",
    "    if(testraw[x][4]==\"male\"):\n",
    "        temp.append(0)\n",
    "    elif(testraw[x][4]==\"female\"):\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(2)\n",
    "        print (\"shit happened\")\n",
    "        \n",
    "    try:\n",
    "        temp.append(float(testraw[x][5])) #age\n",
    "    except ValueError:\n",
    "        temp.append(testAgeAvg)\n",
    "    \n",
    "    temp.append(float(testraw[x][6])) #Siblings/Spouse?\n",
    "    \n",
    "    temp.append(float(testraw[x][7])) #Parent/Child\n",
    "    \n",
    "    try:\n",
    "        temp.append(float(testraw[x][9])) #fare\n",
    "    except ValueError:\n",
    "        temp.append(0)\n",
    "            \n",
    "    if(testraw[x][11]=='S'):\n",
    "        temp.append(1)\n",
    "        temp.append(0)\n",
    "        temp.append(0)\n",
    "    if(testraw[x][11]=='C'):\n",
    "        temp.append(0)\n",
    "        temp.append(1)\n",
    "        temp.append(0)\n",
    "    if(testraw[x][11]=='Q'):\n",
    "        temp.append(0)\n",
    "        temp.append(0)\n",
    "        temp.append(1)\n",
    "    \n",
    "    #print temp\n",
    "    #temp2=[]\n",
    "    #temp2.append(temp)\n",
    "    #temp2.append(testraw[x][0])\n",
    "    #testdat.append(temp2)\n",
    "    testdat.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most ML algorithms work best with feature scaling such that one feature does not overpower the rest.\n",
    "I'm a little worried that the one-hot encoding may cause problems, but there doesn't seem to be much of a problem\n",
    "\"\"\"\n",
    "\n",
    "def normalize(data, col):\n",
    "    coldat = []\n",
    "    for x in range(1, len(data)):\n",
    "        coldat.append(float(data[x][col]))\n",
    "    max=numpy.nanmax(coldat)\n",
    "    min=numpy.nanmin(coldat)\n",
    "    scalefactor=float(max-min)\n",
    "    print max\n",
    "    print min\n",
    "    #print scalefactor\n",
    "    #print ''\n",
    "    for x in range(1, len(data)):\n",
    "        z=float(data[x][col])\n",
    "        z=(z-min)/scalefactor\n",
    "        data[x][col]=z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n",
      "0.42\n",
      "8.0\n",
      "0.0\n",
      "6.0\n",
      "0.0\n",
      "512.3292\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#normalize training data\n",
    "normalize(traindat, 4)\n",
    "normalize(traindat, 5)\n",
    "normalize(traindat, 6)\n",
    "normalize(traindat, 7)\n",
    "#for x in range(1,10):\n",
    "#    print traindat[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.0\n",
      "0.17\n",
      "8.0\n",
      "0.0\n",
      "9.0\n",
      "0.0\n",
      "512.3292\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#normalize test data\n",
    "normalize(testdat, 4)\n",
    "normalize(testdat, 5)\n",
    "normalize(testdat, 6)\n",
    "normalize(testdat, 7)\n",
    "#for x in range(1,10):\n",
    "#    print testdat[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts training data to numpy floats so that it won't be an issue in later conversions\n",
    "for x in range(0,len(traindat)):\n",
    "    for y in range(0,len(traindat[x])):\n",
    "        traindat[x][y]=numpy.float32(traindat[x][y])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts testing data to numpy floats so that it won't be an issue in later conversions\n",
    "for x in range(0,len(testdat)):\n",
    "    for y in range(0,len(testdat[x])):\n",
    "        testdat[x][y]=numpy.float32(testdat[x][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Copying all the values to a new ndarray fixed some shape issues during training.\n",
    "#Also splitting off 91 examples to use as a validation set. The data is shuffled before doing so.\n",
    "#numpy.random.shuffle(traindat)\n",
    "\n",
    "traindatfixed=numpy.zeros((891,11))\n",
    "#trainval=numpy.zeros((91,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy training feature data\n",
    "for x in range(0,len((traindat))):\n",
    "    for y in range(0,len(traindat[x])):\n",
    "        traindatfixed[x][y]=numpy.float32(traindat[x][y])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#copy and one-hot training IV for softmax regression\n",
    "survival = []\n",
    "#survivalval=[]\n",
    "for x in range(0,len(traindat)):\n",
    "    if(float(trainraw[x+1][1])==0):\n",
    "        survival.append(numpy.array([1.0,0.0]))\n",
    "    else:\n",
    "        survival.append(numpy.array([0.0,1.0]))\n",
    "\n",
    "survival = numpy.array(survival)\n",
    "#survivalval = numpy.array(survivalval)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert test data\n",
    "testdatfixed=numpy.zeros((418,11))\n",
    "for x in range(0,len(testdat)):\n",
    "    for y in range(0,len(testdat[x])):\n",
    "        testdatfixed[x][y]=numpy.float32(testdat[x][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.ensemble import RandomForestClassifier \\n\\nforest = RandomForestClassifier(n_estimators = 100)\\n\\nforest = forest.fit(traindatfixed,survival)\\n\\n# Since I reserved some validation data, might as well use it\\nprint (forest.score(traindatfixed,survival))\\n\\nouts = forest.predict(testdatfixed)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity test with scikit-learn random forest, with code from the kaggle tutorial.\n",
    "#Disabled because it loads a deprecated version of BLAS that theano complains about.\n",
    "#Code to convert output to CSV needs tweaks to work;\n",
    "#this outputs [0, 1] or [1, 0], as opposed to [0] or [1] from the NNs.\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "forest = forest.fit(traindatfixed,survival)\n",
    "\n",
    "# Since I reserved some validation data, might as well use it\n",
    "print (forest.score(traindatfixed,survival))\n",
    "\n",
    "outs = forest.predict(testdatfixed)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs a deep neural network on the dataset, uses code from the keras examples. \n",
    "Probably overkill, but this is an exercise anyway.\n",
    "This section contains the imports.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.708169247499\n",
      "Test accuracy: 0.373737373804\n",
      "\n",
      "50\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.368352231621\n",
      "Test accuracy: 0.848484848017\n",
      "\n",
      "100\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.349823465853\n",
      "Test accuracy: 0.851851852521\n",
      "\n",
      "150\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.325372112302\n",
      "Test accuracy: 0.85970819371\n",
      "\n",
      "200\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.316319748592\n",
      "Test accuracy: 0.865319864852\n",
      "\n",
      "250\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.307497302424\n",
      "Test accuracy: 0.874298540497\n",
      "\n",
      "300\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.323957799444\n",
      "Test accuracy: 0.866442200444\n",
      "\n",
      "350\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.289115972909\n",
      "Test accuracy: 0.874298541634\n",
      "\n",
      "400\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.277658376228\n",
      "Test accuracy: 0.883277216611\n",
      "\n",
      "450\n",
      "891/891 [==============================] - 0s     \n",
      "Test score: 0.269654428944\n",
      "Test accuracy: 0.884399551066\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#NN adapted from the Keras examples\n",
    "#I tried an autoencoder in front and hidden layers with <11 nodes. Appears that dimensionality reduction isn't to helpful\n",
    "#A shallow NN with 7 hidden works surprisingly well, as it stands I need to do more feature engineering\n",
    "#Dropout doesn't seem to help all that much, but there's no validation data\n",
    "#I tried splitting off 91 random examples for validation but that hit accuracy quite hard\n",
    "\n",
    "\n",
    "batch_size = 20\n",
    "nb_classes = 2\n",
    "nb_epochs = 50\n",
    "models=[]\n",
    "\n",
    "for x in range(0,10):\n",
    "    nb_epoch=nb_epochs*x\n",
    "    print(nb_epoch)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_shape=(11,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Verbosity disabled since it triggers a juptyer notebook bug and crashes the training\n",
    "\n",
    "    history = model.fit(traindatfixed, survival,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=0, validation_data=(traindatfixed, survival))\n",
    "\n",
    "    score = model.evaluate(traindatfixed, survival, verbose=1)\n",
    "    models.append(model)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('')\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s     \n",
      "[0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1\n",
      " 0 1 1 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n",
      "418/418 [==============================] - 0s     \n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 1 1 1 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Converts things to CSV for Kaggle submission\n",
    "\n",
    "#model=models[0]\n",
    "#outs = model.predict_classes(traindatfixed)\n",
    "#print(outs)\n",
    "outs = model.predict_classes(testdatfixed)\n",
    "#print(outs)\n",
    "\n",
    "output = []\n",
    "output.append([\"PassengerId\",\"Survived\"])\n",
    "\n",
    "for x in range(0,len(outs)):\n",
    "    output.append([testraw[x+1][0],int(outs[x])])\n",
    "    \n",
    "with open(\"outputDNN.csv\", 'wb') as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
